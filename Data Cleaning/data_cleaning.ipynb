{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data.csv', on_bad_lines='skip', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39775\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "data.head()\n",
    "drop_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping probable fake entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n"
     ]
    }
   ],
   "source": [
    "# A value of 1 is checked, 0 means unchecked. The words at VCL6, VCL9, and VCL12 are not real words and can be used as a validity check.\n",
    "drop_count += len(data[(data['VCL6'] == 1) & (data['VCL9'] == 1) & (data['VCL12'] == 1)])\n",
    "print(drop_count)\n",
    "data.drop(data[(data['VCL6'] == 1) & (data['VCL9'] == 1) & (data['VCL12'] == 1)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q1A', 'Q1I', 'Q1E', 'Q2A', 'Q2I', 'Q2E', 'Q3A', 'Q3I', 'Q3E', 'Q4A', 'Q4I', 'Q4E', 'Q5A', 'Q5I', 'Q5E', 'Q6A', 'Q6I', 'Q6E', 'Q7A', 'Q7I', 'Q7E', 'Q8A', 'Q8I', 'Q8E', 'Q9A', 'Q9I', 'Q9E', 'Q10A', 'Q10I', 'Q10E', 'Q11A', 'Q11I', 'Q11E', 'Q12A', 'Q12I', 'Q12E', 'Q13A', 'Q13I', 'Q13E', 'Q14A', 'Q14I', 'Q14E', 'Q15A', 'Q15I', 'Q15E', 'Q16A', 'Q16I', 'Q16E', 'Q17A', 'Q17I', 'Q17E', 'Q18A', 'Q18I', 'Q18E', 'Q19A', 'Q19I', 'Q19E', 'Q20A', 'Q20I', 'Q20E', 'Q21A', 'Q21I', 'Q21E', 'Q22A', 'Q22I', 'Q22E', 'Q23A', 'Q23I', 'Q23E', 'Q24A', 'Q24I', 'Q24E', 'Q25A', 'Q25I', 'Q25E', 'Q26A', 'Q26I', 'Q26E', 'Q27A', 'Q27I', 'Q27E', 'Q28A', 'Q28I', 'Q28E', 'Q29A', 'Q29I', 'Q29E', 'Q30A', 'Q30I', 'Q30E', 'Q31A', 'Q31I', 'Q31E', 'Q32A', 'Q32I', 'Q32E', 'Q33A', 'Q33I', 'Q33E', 'Q34A', 'Q34I', 'Q34E', 'Q35A', 'Q35I', 'Q35E', 'Q36A', 'Q36I', 'Q36E', 'Q37A', 'Q37I', 'Q37E', 'Q38A', 'Q38I', 'Q38E', 'Q39A', 'Q39I', 'Q39E', 'Q40A', 'Q40I', 'Q40E', 'Q41A', 'Q41I', 'Q41E', 'Q42A', 'Q42I', 'Q42E', 'country', 'source', 'introelapse', 'testelapse', 'surveyelapse', 'TIPI1', 'TIPI2', 'TIPI3', 'TIPI4', 'TIPI5', 'TIPI6', 'TIPI7', 'TIPI8', 'TIPI9', 'TIPI10', 'VCL1', 'VCL2', 'VCL3', 'VCL4', 'VCL5', 'VCL6', 'VCL7', 'VCL8', 'VCL9', 'VCL10', 'VCL11', 'VCL12', 'VCL13', 'VCL14', 'VCL15', 'VCL16', 'education', 'urban', 'gender', 'engnat', 'age', 'screensize', 'uniquenetworklocation', 'hand', 'religion', 'orientation', 'race', 'voted', 'married', 'familysize', 'major']\n"
     ]
    }
   ],
   "source": [
    "print(data.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: how the user found the test, 1=from the front page of the site hosting the survey, 2=from google, 0=other or unknown\n",
    "#introelapse: The time spent on the introduction/landing page (in seconds)\n",
    "#surveyelapse: The time spent answering the rest of the demographic and survey questions\n",
    "#VCL 1-16: Check all the words whose definitions you are sure you know\n",
    "#urban: What type of area did you live when you were a child?\", 1=Rural (country side), 2=Suburban, 3=Urban (town, city)\n",
    "#engnat: Is English your native language?\", 1=Yes, 2=No\n",
    "#screensize: 1=device with small screen (phone, etc), 2=device with big screen (laptop, desktop, etc)\n",
    "#uniquenetworklocation: 1=only one survey from user's specific network in dataset, 2=multiple surveys submitted from the network of this user  (2 does not necessarily imply duplicate records for an individual, as it could be different students at a single school or different memebers of the same household; and even if 1 there still could be duplicate records from a single individual e.g. if they took it once on their wifi and once on their phone)\n",
    "#hand: What hand do you use to write with?\", 1=Right, 2=Left, 3=Both\n",
    "#religion: What is your religion?\n",
    "#orientation: What is your sexual orientation?\n",
    "#race: What is your race?\n",
    "#voted: Have you voted in a national election in the past year\n",
    "#major: If you attended a university, what was your major\n",
    "cols_to_drop = ['source', 'introelapse', 'surveyelapse', 'urban', 'engnat', 'screensize', 'uniquenetworklocation', 'hand', 'religion', 'orientation', 'race', 'voted', 'major']\n",
    "vcl = ['VCL' + str(x) for x in range(1, 17)]\n",
    "qi = ['Q' + str(x) + 'I' for x in range(1, 43)]\n",
    "qe = ['Q' + str(x) + 'E' for x in range(1, 43)]\n",
    "cols_to_drop.extend(vcl+qi+qe)\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "for i in range(0, 42):\n",
    "    data.rename(columns = {data.columns[i]: 'Q' + str(i+1)}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with NaN values\n",
    "drop_count += data.isnull().sum().sum()\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting number of columns & rows dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Dropped: 326\n",
      "Columns Dropped: 113\n",
      "Length of Clean Dataframe: 39449\n"
     ]
    }
   ],
   "source": [
    "print('Rows Dropped:', drop_count)\n",
    "print('Columns Dropped:', len(cols_to_drop))\n",
    "print('Length of Clean Dataframe:', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('sdm_data_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b562fef2b654882737c66d0d6be9d3d9ebf739d52502496031a4d30413852c3e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit ('3.10.2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
